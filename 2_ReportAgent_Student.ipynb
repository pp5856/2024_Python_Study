{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pp5856/2024_Python_Study/blob/main/2_ReportAgent_Student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tgWF2j10oSEh",
        "outputId": "d47ed8b8-f383-4c1d-becf-51f09d7aaf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.49)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.22)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.0)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.25-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.4/142.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.2-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=9e8335f3ec99c78efd527c62582c8dd4de0cb1409a4bcc93949d0af5419aaa7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf, filetype, xxhash, python-dotenv, pypdfium2, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, pdfminer.six, langgraph-sdk, dataclasses-json, pdfplumber, langchain-core, langgraph-checkpoint, langchain-text-splitters, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langchain, langgraph, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.49\n",
            "    Uninstalling langchain-core-0.3.49:\n",
            "      Successfully uninstalled langchain-core-0.3.49\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.7\n",
            "    Uninstalling langchain-text-splitters-0.3.7:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.7\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.22\n",
            "    Uninstalling langchain-0.3.22:\n",
            "      Successfully uninstalled langchain-0.3.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 fpdf-1.7.2 google-ai-generativelanguage-0.6.17 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.51 langchain-experimental-0.3.4 langchain-google-genai-2.1.2 langchain-text-splitters-0.3.8 langgraph-0.3.25 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 marshmallow-3.26.1 mypy-extensions-1.0.0 ormsgpack-1.9.1 pdfminer.six-20250327 pdfplumber-0.11.6 pydantic-settings-2.8.1 pypdfium2-4.30.1 python-dotenv-1.1.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4718f66ef9764a2487c88a5602bf6179"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain-google-genai langchain-core langchain-community langchain-experimental fpdf pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4jLETHnXnKBh"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain.schema import AIMessage\n",
        "from typing import Annotated, Literal\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langchain_community.agent_toolkits import FileManagementToolkit\n",
        "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
        "from pydantic import BaseModel, Field\n",
        "from fpdf import FPDF\n",
        "import random\n",
        "import pdfplumber\n",
        "import os\n",
        "import requests\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YtLQpBZQIHsa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "google_api_key = \"AIzaSyDZrbzcM9ap_B-za68X8ZllzJwm5ipYTMk\" # @param {\"type\":\"string\"}\n",
        "tavily_api_key = \"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\" # @param {\"type\":\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y8azdfq-l-ps"
      },
      "outputs": [],
      "source": [
        "os.environ[\"google_api_key\"] = google_api_key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AuwqB6S6nKBl",
        "outputId": "4725ccd4-cb8c-4393-9408-6875728601bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-5-b00a7f08cf91>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-b00a7f08cf91>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    # 상태를 정의해주세요.\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "# 그래프 상태 정의\n",
        "\n",
        "class State(TypedDict):\n",
        "    # 상태를 정의해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-CNSwr0qnsi"
      },
      "outputs": [],
      "source": [
        "# LLM 정의\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-exp-03-25\",\n",
        "#                              temperature=0,\n",
        "#                              convert_system_message_to_human=True)\n",
        "\n",
        "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
        "#                              temperature=0,\n",
        "#                              convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNMa89_7nKBm"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def read_pdf(file_path: str):\n",
        "    \"\"\"\n",
        "    PDF 파일에서 텍스트를 추출하는 도구입니다.\n",
        "    표 형식 또는 일반 텍스트가 포함된 PDF를 읽고 문자열로 반환합니다.\n",
        "\n",
        "    file_path 예시: './report.pdf'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "        return text.strip() if text.strip() else \"❌ PDF에서 텍스트를 추출할 수 없습니다.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ PDF 읽기 오류: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqkLXOw6nKBn"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def write_pdf(content: str, filename: str = \"output.pdf\", summary: bool =True):\n",
        "    \"\"\"\n",
        "    텍스트를 PDF 파일로 저장하는 도구입니다.\n",
        "    PDF형태의 문서로 만들어야할 때 이 도구를 사용하세요.\n",
        "    \"\"\"\n",
        "\n",
        "    if summary:\n",
        "        prompt = PromptTemplate.from_template(\"\"\"\n",
        "                당신은 보고서를 작성하는 어시스턴트입니다. 당신에겐 문서 모음이 제공되고 이를 잘 분석하여 보고서를 작성하여야 합니다.\n",
        "                아래의 content는 문서 모음입니다. 문서의 제목, 본문을 잘 판단하고 정리하여 요약합니다.\n",
        "                항상 구조화된 출력을 제공하세요.\n",
        "                항상 마지막엔 인사이트도 첨부합니다.\n",
        "\n",
        "                content : {content}\n",
        "                \"\"\")\n",
        "\n",
        "        chain = prompt | llm\n",
        "\n",
        "        content = chain.invoke({\"content\":content}).content\n",
        "\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    font_url = \"https://github.com/google/fonts/raw/main/ofl/notosanskr/NotoSansKR%5Bwght%5D.ttf\"\n",
        "    font_path = \"./fonts/NotoSansKR.ttf\"\n",
        "\n",
        "    try:\n",
        "        os.mkdir(\"./fonts/\")\n",
        "        response = requests.get(font_url)\n",
        "        with open(font_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "    font_path = \"./fonts/NotoSansKR.ttf\"\n",
        "\n",
        "    try:\n",
        "        pdf.add_font(\"NotoSans\", \"\", font_path, uni=True)\n",
        "        pdf.set_font(\"NotoSans\", size=12)\n",
        "    except:\n",
        "        raise ValueError(\"한글 폰트를 등록할 수 없습니다.\")\n",
        "\n",
        "    for line in content.split(\"\\n\"):\n",
        "        pdf.multi_cell(0, 10, line)\n",
        "    pdf.output(f\"./{filename}\")\n",
        "\n",
        "    return f\"{filename} 저장 완료\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKMUZEXPIHsc"
      },
      "outputs": [],
      "source": [
        "# 툴 정의\n",
        "# TavilySearchResults : 웹 검색 도구\n",
        "# PythonAstREPLTool : 파이썬 코드 실행 도구\n",
        "# write_pdf : pdf 생성 도구\n",
        "# read_pdf : pdf 읽기 도구\n",
        "# file_delete : 파일 삭제 도구\n",
        "# list_directory : 파일 목록 읽기 도구\n",
        "\n",
        "tools = [TavilySearchResults(max_results=10), PythonAstREPLTool(), write_pdf, read_pdf, *FileManagementToolkit(\n",
        "                                                                            selected_tools=[\"file_delete\",\"list_directory\"]).get_tools()]\n",
        "search_tool, code_tool, write_tool, read_tool, delete_tool, listdir_tool= tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uOvOZf3nKBn"
      },
      "outputs": [],
      "source": [
        "# LLM에게 도구 할당\n",
        "\n",
        "llm_with_tools = # LLM에게 도구를 할당해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrMAISv-nKBo"
      },
      "outputs": [],
      "source": [
        "# 단기 기억(history)으로 추출 함수\n",
        "\n",
        "def shorterm_memory(state:State):\n",
        "\n",
        "    if len(state[\"messages\"]) # ?:\n",
        "        # 원하는 길이만큼 단기기억을 설정해보세요.\n",
        "    elif len(state[\"messages\"]) == 1:\n",
        "        history = \"\"\n",
        "    else:\n",
        "        history = state[\"messages\"][:-1]\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsqpQmxknKBo"
      },
      "outputs": [],
      "source": [
        "class HistoryChecker(BaseModel):\n",
        "    \"\"\"\n",
        "    이전의 대화 기록을 참고하여 질문에 대해 답변할 수 있는지 판단합니다.\n",
        "    답변할 수 있다면 \"yes\", 답변할 수 없다면 \"no\"를 반환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    yes_no : Literal[\"yes\", \"no\"] = Field(..., description=\"\"\"Use your previous conversation history to determine if you can answer your questions.\n",
        "    Return \"yes\" if you can answer, \"no\" if you can't answer.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SsCloETnKBp"
      },
      "outputs": [],
      "source": [
        "# 히스토리 기반 답변 분기를 위한 함수 설정\n",
        "\n",
        "def history_check(state:State):\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                이전의 대화 기록을 참고하여 질문에 대해 답변할 수 있는지 판단합니다.\n",
        "                답변할 수 있다면 \"yes\", 답변할 수 없다면 \"no\"를 반환합니다.\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "    chain = prompt | history_checker\n",
        "\n",
        "    history = shorterm_memory(state)\n",
        "\n",
        "    result = chain.invoke({\"history\":history,\n",
        "                            \"query\":state[\"query\"]})\n",
        "\n",
        "    return result.yes_no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDAlnV3dnKBp"
      },
      "outputs": [],
      "source": [
        "# LLM의 응답을 HistoryChecker 클래스 구조에 맞춰 파싱하도록 설정\n",
        "\n",
        "history_checker = llm.with_structured_output(HistoryChecker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fx8dfRdlnKBp"
      },
      "outputs": [],
      "source": [
        "# 기억 기반 답변 노드\n",
        "\n",
        "def memory_chat(state:State):\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                이전의 대화 기록을 참고하여 질문에 대해 답변하세요.\n",
        "                아래 대화 기록을 첨부합니다.\n",
        "                대화 기록을 통해 답변이 어렵다면 내부 지식을 참조하세요.\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "\n",
        "    chain = prompt | llm\n",
        "\n",
        "    history = shorterm_memory(state)\n",
        "\n",
        "    result = chain.invoke({\"history\":history,\n",
        "                           \"query\":state[\"query\"]})\n",
        "\n",
        "    if len(state[\"tool_call\"]) == 0:\n",
        "        return # \"answer\"는 result.content, \"messages\"는 result, \"tool_call\"은 \"사용된 기록 없음\" 으로 설정하여 상태를 업데이트 합니다.\n",
        "\n",
        "    else:\n",
        "        return # \"answer\"는 result.content, \"messages\"는 result로 상태를 업데이트합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLm8qqC7nKBq"
      },
      "outputs": [],
      "source": [
        "# 기억 기반 답변 분기 노드\n",
        "\n",
        "def history_node(state:State):\n",
        "    if len(state[\"messages\"]) == 1:\n",
        "        return {\"answer\":\"답변 없음\",\n",
        "                \"tool_call\":\"사용된 도구 없음\"}\n",
        "    else:\n",
        "        return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVxNiGN0nKBq"
      },
      "outputs": [],
      "source": [
        "# 도구 선택 노드\n",
        "\n",
        "def select(\n",
        "    state: State,\n",
        "):\n",
        "\n",
        "\n",
        "    # 프롬프트를 구성해주세요.\n",
        "    # 도구를 적절히 선택할 수 있도록 하여야합니다.\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "                대화 기록 : {history}\n",
        "\n",
        "                최근 사용한 도구 : {tool_name}\n",
        "\n",
        "                정답 : {answer}\n",
        "\n",
        "                질문 : {query}\n",
        "\n",
        "                \"\"\")\n",
        "\n",
        "    # 체인을 구성해주세요.\n",
        "    chain =\n",
        "\n",
        "    history = shorterm_memory(state)\n",
        "\n",
        "    # 체인을 작동시켜주세요\n",
        "    result =\n",
        "\n",
        "    if hasattr(result, \"tool_calls\") and len(result.tool_calls) > 0:\n",
        "        tool_calls = result.tool_calls\n",
        "\n",
        "        return {\"messages\": result,\n",
        "                \"tool_call\":tool_calls}\n",
        "    else:\n",
        "        return {\"messages\":AIMessage(content=f\"\"\"도구를 선택하지 못했습니다. 적절한 도구를 재선택하세요.\n",
        "                                        \"\"\"),\n",
        "                                    \"tool_call\":\"선택된 도구 없음\"}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6s0RyEfnKBq"
      },
      "outputs": [],
      "source": [
        "# 도구 실행 노드\n",
        "\n",
        "tool_node = # ToolNode에 도구를 부여하여 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD-vMnQenKBq"
      },
      "outputs": [],
      "source": [
        "class AnswerChecker(BaseModel):\n",
        "    \"\"\"\n",
        "    정답 분류기입니다.\n",
        "\n",
        "    정답이 질문을 해결했는지 여부를 판단합니다.\n",
        "    질문을 해결하지 못했을 시 해결될 때까지 도구를 이용합니다.\n",
        "\n",
        "    질문을 해결했다면 \"end\", 해결하지 못했다면 \"tool\"을 반환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    end : Literal[\"end\", \"tool\"] = Field(..., description=\"\"\"You are the answer sorter.\n",
        "\n",
        "                                                                Determine if the correct answer has solved the question.\n",
        "                                                                If the question is not resolved, use the tool until it is resolved.\n",
        "\n",
        "                                                                Return \"end\" if you solved the question, or \"tool\" if you didn't.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51lPyxhdnKBr"
      },
      "outputs": [],
      "source": [
        "# LLM의 응답을 AnswerChecker 클래스 구조에 맞춰 파싱하도록 설정\n",
        "\n",
        "answer_checker = # LLM이 구조화된 답변을 할 수 있도록 설정해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyZTkR8fnKBr"
      },
      "outputs": [],
      "source": [
        "# 답변 확인 노드\n",
        "\n",
        "def response(state:State):\n",
        "\n",
        "    return {\"answer\":state[\"messages\"][-1]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBV4ASvjnKBr"
      },
      "outputs": [],
      "source": [
        "# 답변 완성 판단 분기 함수\n",
        "\n",
        "def answer_check(state:State):\n",
        "\n",
        "    # 프롬프트를 구성해주세요.\n",
        "    # 질문이 해결됐는지 잘 판단할 수 있는 프롬프트를 만들어야 합니다.\n",
        "\n",
        "    prompt = PromptTemplate.from_template(\"\"\"\n",
        "\n",
        "    History : {history}\n",
        "\n",
        "    정답 : {answer}\n",
        "\n",
        "    질문 : {query}\n",
        "    \"\"\")\n",
        "\n",
        "    chain = # 체인을 구성해주세요.\n",
        "\n",
        "    history = # 단기기억을 가져오세요.\n",
        "\n",
        "    result = # 체인을 작동시켜주세요.\n",
        "\n",
        "    return result.end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50EDu4mOnKBr"
      },
      "outputs": [],
      "source": [
        "# 그래프 정의\n",
        "\n",
        "graph_builder = # 그래프를 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDdqjxeNnKBr"
      },
      "outputs": [],
      "source": [
        "# 노드 및 엣지 정의\n",
        "\n",
        "# 로직을 잘 보고 노드와 엣지를 구성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Z71CK8nKBr"
      },
      "outputs": [],
      "source": [
        "# 메모리 설정 및 그래프 컴파일\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ2jWtlinKBs"
      },
      "outputs": [],
      "source": [
        "# 그래프 시각화\n",
        "# 가끔 \"ReadTimeout: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)\"라는 에러가 발생\n",
        "# 시간 초과로 그래프 생성에 실패했다는 메시지일뿐 기능과는 관계없으니 진행해도 괜찮습니다.\n",
        "\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWcfKPoOnKBr"
      },
      "outputs": [],
      "source": [
        "# config 재생성 노드, config의 재사용은 고려되지 않음. 재사용한다면 변수에 할당하여 사용할 것\n",
        "\n",
        "def reset_config(limit=20):\n",
        "\n",
        "    thread_id=random.randint(1,999999)\n",
        "\n",
        "    config = RunnableConfig(recursion_limit=limit, configurable={\"thread_id\": thread_id})\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07_bBQgHnKBs"
      },
      "outputs": [],
      "source": [
        "# 출력 함수 정의\n",
        "# mode = \"values\" : 상태의 키, 값의 형태로 반환\n",
        "# mode = \"updates\" : 업데이트되는 값만 반환\n",
        "\n",
        "def streaming(query, config, mode=\"values\"):\n",
        "\n",
        "    result = graph.stream({\"messages\":(\"user\", query),\n",
        "                         \"query\":query}, config=config, stream_mode=mode)\n",
        "\n",
        "    if mode == \"values\":\n",
        "        for step in result:\n",
        "            for k, v in step.items():\n",
        "                if k == \"messages\":\n",
        "                    v[-1].pretty_print()\n",
        "    elif mode == \"updates\":\n",
        "        for step in result:\n",
        "            for k,v in step.items():\n",
        "                print(f\"\\n\\n=== {k} ===\\n\\n\")\n",
        "                print(v)\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI6E1DvhnKBs"
      },
      "outputs": [],
      "source": [
        "config = reset_config()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 에이전트에게 자유롭게 질문해주세요."
      ],
      "metadata": {
        "id": "A_mJWtfCkN9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Modulabs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}